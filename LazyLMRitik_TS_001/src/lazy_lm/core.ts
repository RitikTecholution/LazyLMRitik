// AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_core.ipynb.

import { config } from 'dotenv';
import { AnthropicVertex, Message, MessageParam } from '@anthropic-ai/sdk';
import { dataclass, field } from 'ts-dataclass';

// Swagger documentation
/**
 * @swagger
 * components:
 *   schemas:
 *     LazyState:
 *       type: object
 *       properties:
 *         problem: 
 *           type: string
 *         steps: 
 *           type: array
 *           items:
 *             type: string
 *         current_step: 
 *           type: number
 *     LLM:
 *       type: object
 *       properties:
 *         client: 
 *           $ref: '#/components/schemas/AnthropicVertex'
 *         model: 
 *           type: string
 */

@dataclass
class LazyState {
    problem: string;
    steps: string[] = field(() => []);
    current_step: number = 0;

    constructor(problem: string) {
        this.problem = problem;
        this.steps.push(problem);
    }

    add_step(step: string): void {
        this.steps.push(step);
        this.current_step++;
    }

    get_context(): string {
        return `Problem: ${this.problem} \n Steps so far: ${this.steps}`;
    }

    refresh(): void {
        this.current_step = 0;
        this.steps = [this.problem];
    }
}

@dataclass
class LLM {
    client: AnthropicVertex;
    model: string;
}

const lazy_system_p = `
You are a helpful assistant that can help with math problems.
You will be given a problem and a list of steps as context, the format will be:
        
PROBLEM: <problem>
STEPS: <steps>

Your job is to complete the next step and only the next step in the problem-solving process. You should never give more than one step.
If you evaluate that the problem is done, respond with "PROBLEM DONE"
`;

/**
 * @swagger
 * components:
 *   schemas:
 *     LazyEvaluationClient:
 *       type: object
 *       properties:
 *         model: 
 *           type: string
 *         client: 
 *           $ref: '#/components/schemas/AnthropicVertex'
 *         max_tokens: 
 *           type: number
 *         state: 
 *           $ref: '#/components/schemas/LazyState'
 *         lazy_system_p: 
 *           type: string
 *         question_history: 
 *           type: array
 *           items:
 *             type: string
 */
class LazyEvaluationClient {
    model: string;
    client: AnthropicVertex;
    max_tokens: number;
    state: LazyState | null;
    lazy_system_p: string;
    question_history: string[];

    constructor(
        llm: LLM,
        max_tokens: number = 100,
        state: LazyState | null = null,
        lazy_system_p: string = lazy_system_p
    ) {
        this.model = llm.model;
        this.client = llm.client;
        this.max_tokens = max_tokens;
        this.state = state;
        this.lazy_system_p = lazy_system_p;
        this.question_history = [];
    }

    initalize_problem(problem: string): void {
        this.state = new LazyState(problem);
    }

    get_current_step(): string {
        if (!this.state) {
            throw new Error("Problem is not initialized, call initalize_problem first");
        }
        return this.state.steps[this.state.current_step];
    }

    async get_next_step(): Promise<string> {
        if (!this.state) {
            throw new Error("Problem is not initialized, call initalize_problem first");
        }

        const messages: MessageParam[] = [
            {
                role: "user",
                content: this.state.get_context()
            }
        ];

        const response = await this.client.messages.create({
            system: this.lazy_system_p,
            model: this.model,
            messages: messages,
            max_tokens: this.max_tokens
        });

        const next_step = response.content[0].text;
        if (next_step) {
            this.state.add_step(next_step.trim());
            return next_step.trim();
        } else {
            throw new Error("No next step found");
        }
    }

    /**
     * Allows the user to ask a question about the current step without affecting the model's ability to generate the next step.
     * @param question The question the user wants to ask about the current step.
     * @returns The model's response to the question.
     */
    async ask_question(question: string): Promise<string> {
        if (!this.state) {
            throw new Error("Problem is not initialized, call initalize_problem first");
        }

        const current_state = `
            System: ${this.lazy_system_p}
            Problem: ${this.state.problem}
            Context: ${this.state.get_context()}
            Current step: ${this.state.steps[this.state.current_step]}
        `;

        const prompt = `
            Question History: ${this.question_history}
            Question: ${question}
            Please answer the question without advancing to the next step.
            If you are asked to provide an example for a specific step, please provide an example that is not in the current context.
        `;

        const messages: MessageParam[] = [
            {
                role: "user",
                content: prompt
            }
        ];

        const response = await this.client.messages.create({
            system: current_state,
            model: this.model,
            messages: messages,
            max_tokens: this.max_tokens
        });

        const answer = response.content[0].text.trim();
        this.question_history.push(question);
        this.question_history.push(answer);

        return answer;
    }
}

/**
 * Entry point of the LazyLM Framework for the `AnthropicVertex` client API
 * @param problem The problem to initialize the LazyEvaluationClient with
 * @returns A new LazyEvaluationClient instance
 */
AnthropicVertex.prototype.lazy = function(problem: string): LazyEvaluationClient {
    const state = new LazyState(problem);
    const llm = new LLM(this, "claude-3-5-sonnet@20240620");
    return new LazyEvaluationClient(llm, 100, state);
};

export { lazy_system_p, LazyState, LLM, LazyEvaluationClient };