{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LazyLM Core\n",
    "\n",
    "> Core LazyLM classes, types, and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| export\n",
    "from dotenv import load_dotenv\n",
    "from anthropic import AnthropicVertex\n",
    "from anthropic.types import (\n",
    "    MessageParam,\n",
    "    Message\n",
    ")\n",
    "from fastcore.basics import *\n",
    "from fastcore.test import *\n",
    "from fastcore.foundation import *\n",
    "from dataclasses import (\n",
    "    dataclass,\n",
    "    field\n",
    ")\n",
    "from typing import (\n",
    "    List,\n",
    "    Optional\n",
    ")\n",
    "import os\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ce-demo-space', 'us-east5', 'claude-3-5-sonnet@20240620')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "project_id = os.getenv(\"PROJECT_ID\")\n",
    "location = os.getenv(\"PROJECT_LOCATION\")\n",
    "model = os.getenv(\"CLAUDE_MODEL\")\n",
    "\n",
    "(project_id, location, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the state called `LazyState` that will be passed to the language model. This should essentially be able to do the following:\n",
    "\n",
    "- Keep track of the original problem\n",
    "- Keep track of all of the steps done so far\n",
    "- get the current step\n",
    "- add a new step\n",
    "- refresh the state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@dataclass\n",
    "class LazyState:\n",
    "    problem: str\n",
    "    steps: List[str] = field(default_factory=list)\n",
    "    current_step: int = 0\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.steps.append(self.problem)\n",
    "\n",
    "    def add_step(self, step: str):\n",
    "        self.steps.append(step)\n",
    "        self.current_step += 1\n",
    "\n",
    "    def get_context(self) -> str:\n",
    "        return f\"Problem: {self.problem} \\n Steps so far: {self.steps}\"\n",
    "\n",
    "    def refresh(self) -> None:\n",
    "        self.current_step = 0\n",
    "        self.steps = [self.problem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LazyState(problem='What is the result of f(x) = 3x + 2 when x = 5?', steps=['What is the result of f(x) = 3x + 2 when x = 5?', 'First, we need substitute x in the function with 5'], current_step=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = LazyState(problem=\"What is the result of f(x) = 3x + 2 when x = 5?\")\n",
    "state.add_step(\"First, we need substitute x in the function with 5\")\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Problem: What is the result of f(x) = 3x + 2 when x = 5? \\n Steps so far: ['What is the result of f(x) = 3x + 2 when x = 5?', 'First, we need substitute x in the function with 5']\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.get_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep things general, we'll have a very simple data class called `LLM` that will give us an interface for the language model client and the model version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class LLM:\n",
    "    client: AnthropicVertex\n",
    "    model: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This package will also keep support for our internal system prompt, called `lazy_system_p`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "lazy_system_p = \"\"\"\n",
    "        You are a helpful assistant that can help with math problems.\n",
    "        You will be given a problem and a list of steps as context, the format will be:\n",
    "                \n",
    "        PROBLEM: <problem>\n",
    "        STEPS: <steps>\n",
    "\n",
    "        Your job is to complete the next step and only the next step in the problem-solving process. You should never give more than one step.\n",
    "        If you evaluate that the problem is done, respond with \"PROBLEM DONE\"\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this simple state manager, we have a way to track each step of the problem-solving process and get the current context to be used for a call to a language model.\n",
    "\n",
    "Now, let's set up a class `LazyEvaluationClient` that will do the heavy lifting of managing the state and calling the language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LazyEvaluationClient:\n",
    "    \"\"\"The Lazy Evaluation Client\"\"\"\n",
    "    def __init__(self, \n",
    "                 llm: LLM, # the language model to use, see `LLM` class\n",
    "                 max_tokens: int = 100, # the maximum number of tokens to generate\n",
    "                 state: Optional[LazyState] = None,\n",
    "                 lazy_system_p: str = lazy_system_p\n",
    "                ):\n",
    "        self.model = llm.model\n",
    "        self.client = llm.client\n",
    "        self.max_tokens = max_tokens\n",
    "        self.state = state\n",
    "        self.lazy_system_p = lazy_system_p\n",
    "        self.question_history = []\n",
    "\n",
    "    def initalize_problem(self, problem: str) -> None:\n",
    "        self.state = LazyState(problem=problem)\n",
    "    \n",
    "    def get_current_step(self) -> str:\n",
    "        return self.state.steps[self.state.current_step]\n",
    "    \n",
    "    def get_next_step(self) -> str:\n",
    "        if self.state is None:\n",
    "            raise ValueError(\"Problem is not initialized, call initalize_problem first\")\n",
    "\n",
    "        messages: List[MessageParam] = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": self.state.get_context()\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        response: Message = self.client.messages.create(\n",
    "            system=self.lazy_system_p,\n",
    "            model=self.model,\n",
    "            messages=messages,\n",
    "            max_tokens=self.max_tokens\n",
    "        )\n",
    "        next_step = response.content[0].text\n",
    "        if next_step is not None:\n",
    "            self.state.add_step(next_step.strip())\n",
    "            return next_step.strip()\n",
    "        else:\n",
    "            raise ValueError(\"No next step found\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of using `LLM`, `LazyState`, and `LazyEvaluationClient` together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_state = LazyState(problem=\"What is the derivative of `2x^3 + x^2 + 2x + 1`? Give me the solution step-by-step\")\n",
    "client = AnthropicVertex(project_id=project_id, region=location)\n",
    "llm = LLM(client=client, model=model)\n",
    "lazy_lm = LazyEvaluationClient(llm=llm, state=lazy_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's grab the current step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the derivative of `2x^3 + x^2 + 2x + 1`? Give me the solution step-by-step'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lazy_lm.get_current_step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To find the derivative of the given function, we'll use the power rule and the constant rule of differentiation. Let's start with the first term:\\n\\nThe derivative of 2x^3 is:\\n3 * 2x^(3-1) = 6x^2\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lazy_lm.get_next_step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the next..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Let's proceed with the next step in finding the derivative:\\n\\nThe derivative of x^2 is:\\n2 * x^(2-1) = 2x\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lazy_lm.get_next_step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at our current state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "What is the derivative of `2x^3 + x^2 + 2x + 1`? Give me the solution step-by-step\n",
      "----------\n",
      "To find the derivative of the given function, we'll use the power rule and the constant rule of differentiation. Let's start with the first term:\n",
      "\n",
      "The derivative of 2x^3 is:\n",
      "3 * 2x^(3-1) = 6x^2\n",
      "----------\n",
      "Let's proceed with the next step in finding the derivative:\n",
      "\n",
      "The derivative of x^2 is:\n",
      "2 * x^(2-1) = 2x\n"
     ]
    }
   ],
   "source": [
    "for step in lazy_lm.state.steps:\n",
    "    print(\"-\"*10)\n",
    "    print(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a way to take the current reasoning step and query it without having the model advance to the next step in the problem-solving process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def ask_question(self:LazyEvaluationClient, question:str) -> Message:\n",
    "    \"\"\"\n",
    "    Allows the user to ask a question about the current step without affecting the model's ability to generate the next step.\n",
    "    \n",
    "    Args:\n",
    "    question (str): The question the user wants to ask about the current step.\n",
    "    \n",
    "    Returns:\n",
    "    str: The model's response to the question.\n",
    "    \"\"\"\n",
    "\n",
    "    current_state = f\"\"\"\n",
    "        System: {self.lazy_system_p}\n",
    "        Problem: {self.state.problem}\\n\n",
    "        Context: {self.state.get_context()}\n",
    "        Current step: {self.state.steps[self.state.current_step]}\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "        Question History: {self.question_history}\n",
    "        Question: {question}\\n\n",
    "        Please answer the question without advancing to the next step.\n",
    "        If you are asked to provide an example for a specific step, please provide an example that is not in the current context.\n",
    "    \"\"\"\n",
    "\n",
    "    messages: List[MessageParam] = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response: Message = self.client.messages.create(\n",
    "            system=current_state,\n",
    "            model=self.model,\n",
    "            messages=messages,\n",
    "            max_tokens=self.max_tokens\n",
    "        )\n",
    "    self.question_history.append(question)\n",
    "    self.question_history.append(response.content[0].text.strip())\n",
    "    \n",
    "    return response.content[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Let's proceed with the next step in finding the derivative:\\n\\nThe derivative of x^2 is:\\n2 * x^(2-1) = 2x\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lazy_lm.get_current_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I apologize for the confusion. Let me explain the current step without advancing further:\\n\\nThe step we're looking at is finding the derivative of the x^2 term in the original expression 2x^3 + x^2 + 2x + 1.\\n\\nTo find the derivative of x^2, we use the power rule of differentiation. The power rule states that for a term ax^n, the derivative is n * ax^(n-1\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lazy_lm.ask_question(\"This does not make sense to me\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Lazy Evaluation Flow \n",
    "\n",
    "This simple framework effectivly shows how we can wrape a language model capable of step-by-step reasoning to create a lazy evaluator.\n",
    "\n",
    "This approach follows these system design steps:\n",
    "\n",
    "- Problem Initialization: A state manager is initalized with a problem\n",
    "\n",
    "- Prompting Strategy: Prompt the language model to generate the next step given the context in the state manager.\n",
    "\n",
    "- State Update: State Manager records the newly generated step and updates.\n",
    "\n",
    "- User Interaction: User interaction is held within a different state manager `question_history` which does not affect the overall state of the current problem.\n",
    "\n",
    "- Adaptive Response: Based on the current input, the Lazy Evaluator decides to either 1) Generate the next step or 2) Provide a response to the user's question given the current state of the problem and the question history."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's patch different model provider's APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def lazy(self: AnthropicVertex, problem: str) -> LazyEvaluationClient:\n",
    "    \"\"\"\n",
    "    Entry point of the LazyLM Framework for the `AnthropicVertex` client API\n",
    "    \"\"\"\n",
    "    state = LazyState(problem=problem)\n",
    "    llm = LLM(client=self, model=\"claude-3-5-sonnet@20240620\")\n",
    "    return LazyEvaluationClient(llm=llm, state=state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
